{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Concat Files, create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (577942, 10)\n",
      "Item DataFrame shape: (255603, 7)\n",
      "Validation DataFrame shape: (112184, 4)\n",
      "\n",
      "Train DataFrame Head:\n",
      "                                              userId    userType  historySize  \\\n",
      "0  f98d1132f60d46883ce49583257104d15ce723b3bbda21...  Non-Logged            3   \n",
      "1  2c1080975e257ed630e26679edbe4d5c850c65f3e09f65...  Non-Logged           60   \n",
      "2  0adffd7450d3b9840d8c6215f0569ad942e782fb19b805...      Logged          107   \n",
      "3  c1e8d644329a78ea1f994292db624c57980b2886cfbc2d...  Non-Logged           56   \n",
      "4  e777d1f31d4d955b63d60acc13df336d3903f52ab8f8f4...  Non-Logged            4   \n",
      "\n",
      "                                             history  \\\n",
      "0  c8aab885-433d-4e46-8066-479f40ba7fb2, 68d2039c...   \n",
      "1  3325b5a1-979a-4cb3-82b6-63905c9edbe8, fe856057...   \n",
      "2  04756569-593e-4133-a95a-83d35d43dbbd, 29b6b142...   \n",
      "3  1f2b9c2f-a2d2-4192-b009-09065da8ec23, 04756569...   \n",
      "4  bebdeb3e-1699-43e0-a1b8-989f5a6ab679, f4b484a7...   \n",
      "\n",
      "                                    timestampHistory  \\\n",
      "0        1657146417045, 1657146605778, 1657146698738   \n",
      "1  1656684240278, 1656761266729, 1656761528085, 1...   \n",
      "2  1656678946256, 1656701076495, 1656701882565, 1...   \n",
      "3  1658333312180, 1658404553818, 1658408449062, 1...   \n",
      "4  1658766608801, 1658766608801, 1660084035094, 1...   \n",
      "\n",
      "                               numberOfClicksHistory  \\\n",
      "0                                         76, 38, 41   \n",
      "1  7, 80, 2, 1, 7, 62, 26, 44, 4, 4, 14, 45, 13, ...   \n",
      "2  0, 0, 0, 0, 0, 44, 0, 0, 2, 1, 0, 0, 0, 44, 0,...   \n",
      "3  8, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 1, 1...   \n",
      "4                                     579, 579, 7, 2   \n",
      "\n",
      "                                   timeOnPageHistory  \\\n",
      "0                                20380, 21184, 35438   \n",
      "1  6049, 210489, 8672, 10000, 30000, 123007, 9965...   \n",
      "2  311274, 140000, 32515, 157018, 118689, 159243,...   \n",
      "3  182696, 91925, 30000, 273655, 126409, 42980, 1...   \n",
      "4                       801396, 801396, 10000, 10000   \n",
      "\n",
      "                             scrollPercentageHistory  \\\n",
      "0                                 50.3, 18.18, 16.46   \n",
      "1  25.35, 45.66, 35.3, 28.05, 36.53, 47.57, 55.33...   \n",
      "2  67.58, 47.22, 41.52, 63.09, 51.38, 65.11, 71.9...   \n",
      "3  58.26, 72.66, 22.57, 59.89, 40.36, 36.35, 14.7...   \n",
      "4                          78.74, 78.74, 16.71, 9.34   \n",
      "\n",
      "                              pageVisitsCountHistory  \\\n",
      "0                                            2, 1, 1   \n",
      "1  1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1...   \n",
      "2  1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1...   \n",
      "3  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
      "4                                         7, 7, 1, 1   \n",
      "\n",
      "                                timestampHistory_new  \n",
      "0        1657146417045, 1657146605778, 1657146698738  \n",
      "1  1656684240278, 1656761266729, 1656761528085, 1...  \n",
      "2  1656678946256, 1656701076495, 1656701882565, 1...  \n",
      "3  1658333312180, 1658404553818, 1658408449062, 1...  \n",
      "4  1658766608801, 1658766608801, 1660084035094, 1...  \n",
      "\n",
      "Item DataFrame Head:\n",
      "                                   page  \\\n",
      "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
      "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
      "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
      "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
      "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
      "1  http://g1.globo.com/pa/santarem-regiao/noticia...   \n",
      "2  http://g1.globo.com/mundo/noticia/2022/07/08/e...   \n",
      "3  http://g1.globo.com/politica/noticia/2021/09/0...   \n",
      "4  http://g1.globo.com/politica/noticia/2021/09/1...   \n",
      "\n",
      "                      issued                   modified  \\\n",
      "0  2022-06-18 20:37:45+00:00  2023-04-15 00:02:08+00:00   \n",
      "1  2019-06-20 17:19:52+00:00  2023-06-16 20:19:15+00:00   \n",
      "2  2022-07-08 08:55:52+00:00  2023-04-15 04:25:39+00:00   \n",
      "3  2021-09-09 19:06:46+00:00  2023-06-07 17:44:54+00:00   \n",
      "4  2021-09-15 19:16:13+00:00  2023-06-07 17:43:39+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  Caso Bruno e Dom: 3º suspeito tem prisão tempo...   \n",
      "1  Linguajar dos santarenos é diferenciado e chei...   \n",
      "2  Ex-premiê Shinzo Abe morre após ser baleado no...   \n",
      "3  Relator no STF, Fachin vota contra marco tempo...   \n",
      "4  \\nApós 2 votos, pedido de vista suspende julga...   \n",
      "\n",
      "                                                body  \\\n",
      "0  Após audiência de custódia, a Justiça do Amazo...   \n",
      "1  Vista aérea de Santarém\\nÁdrio Denner/ AD Prod...   \n",
      "2  Novo vídeo mostra que assassino de Shinzo Abe ...   \n",
      "3  Relator no STF, Fachin vota contra marco tempo...   \n",
      "4  Após um pedido de vista (mais tempo para análi...   \n",
      "\n",
      "                                             caption  \n",
      "0  Jeferson da Silva Lima foi escoltado por agent...  \n",
      "1  As expressões santarenas não significam apenas...  \n",
      "2  Ex-primeiro-ministro foi atingido por tiros de...  \n",
      "3  Ministro defendeu que posse indígena é diferen...  \n",
      "4  Pelo marco temporal, índios só podem reivindic...  \n",
      "\n",
      "Validation DataFrame Head\n",
      "                                              userId userType  \\\n",
      "0  e25fbee3a42d45a2914f9b061df3386b2ded2d8cc1f3d4...   Logged   \n",
      "1  d0afad7ea843d86597d822f0df1d39d31a3fea7c39fdee...   Logged   \n",
      "2  755062dd39a48809880cf363b04268c3af2c003088cde0...   Logged   \n",
      "3  ec1639851d99586c7f4da928deb49187303aec6e3b8d66...   Logged   \n",
      "4  a120515626fe5d12b22b7d5a7c5008912cc69284aa26cc...   Logged   \n",
      "\n",
      "                                             history  \\\n",
      "0  ['be89a7da-d9fa-49d4-9fdc-388c27a15bc8'\\n '01c...   \n",
      "1           ['77901133-aee7-4f7b-afc0-652231d76fe9']   \n",
      "2           ['857aa90f-a7ec-410d-ba82-dfa4f85d4e71']   \n",
      "3  ['b7b90e18-7613-4ca0-a8fc-fd69addfcd85'\\n '835...   \n",
      "4  ['9c764c3a-f9f8-4fb2-b2c4-6331eaeb3dd6'\\n 'b8e...   \n",
      "\n",
      "                                    timestampHistory  \n",
      "0                      [1660533136590 1660672113513]  \n",
      "1                                    [1660556860253]  \n",
      "2                                    [1660561649242]  \n",
      "3  [1660533830245 1660540831707 1660542659111 166...  \n",
      "4        [1660548813953 1660572329731 1660594848200]  \n",
      "Missing values in train_df BEFORE cleaning:\n",
      "userId                     0\n",
      "userType                   0\n",
      "historySize                0\n",
      "history                    0\n",
      "timestampHistory           0\n",
      "numberOfClicksHistory      0\n",
      "timeOnPageHistory          0\n",
      "scrollPercentageHistory    0\n",
      "pageVisitsCountHistory     0\n",
      "timestampHistory_new       0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in item_df BEFORE cleaning:\n",
      "page        0\n",
      "url         0\n",
      "issued      0\n",
      "modified    0\n",
      "title       0\n",
      "body        0\n",
      "caption     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in validation_df BEFORE cleaning:\n",
      "userId              0\n",
      "userType            0\n",
      "history             0\n",
      "timestampHistory    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- Concatena os arquivos de treinamento ---\n",
    "# Usa glob para encontrar todos os arquivos CSV que correspondem ao padrão './training/treino_parte*.csv'\n",
    "train_files = glob.glob('./training/treino_parte*.csv')\n",
    "train_dfs = []\n",
    "for file in train_files:\n",
    "    df = pd.read_csv(file)\n",
    "    train_dfs.append(df)\n",
    "train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "\n",
    "item_files = glob.glob('./itens/itens-parte*.csv')\n",
    "item_dfs = []\n",
    "for file in item_files:\n",
    "    df = pd.read_csv(file)\n",
    "    item_dfs.append(df)\n",
    "item_df = pd.concat(item_dfs, ignore_index=True)\n",
    "\n",
    "validation_df = pd.read_csv('./validacao.csv')\n",
    "\n",
    "# Mostra as dimensões dos DataFrames para verificação\n",
    "print(f\"Train DataFrame shape: {train_df.shape}\")\n",
    "print(f\"Item DataFrame shape: {item_df.shape}\")\n",
    "print(f\"Validation DataFrame shape: {validation_df.shape}\")\n",
    "\n",
    "# Mostra as primeiras linhas para verificação\n",
    "print(\"\\nTrain DataFrame Head:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nItem DataFrame Head:\")\n",
    "print(item_df.head())\n",
    "print(\"\\nValidation DataFrame Head\")\n",
    "print(validation_df.head())\n",
    "\n",
    "# --- Verificando por items faltando antes da limpeza ---\n",
    "print(\"Missing values in train_df BEFORE cleaning:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in item_df BEFORE cleaning:\")\n",
    "print(item_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in validation_df BEFORE cleaning:\")\n",
    "print(validation_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Clean up datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty histories in train_df_cleaned: 0\n",
      "Number of empty histories in validation_df_cleaned: 0\n",
      "\n",
      "Train Data Timestamp Range: Min = 1656644400247, Max = 1660532387472\n",
      "Validation Data Timestamp Range: Min = 1660532401657, Max = 1660705198494\n",
      "\n",
      "In Datetime format:\n",
      "Train Data Timestamp Range: Min = 2022-07-01 03:00:00.247000, Max = 2022-08-15 02:59:47.472000\n",
      "Validation Data Timestamp Range: Min = 2022-08-15 03:00:01.657000, Max = 2022-08-17 02:59:58.494000\n"
     ]
    }
   ],
   "source": [
    "# --- Tratando o campo History dos datasets train_df e validation_df --- #\n",
    "\n",
    "def clean_history_string(history_str):\n",
    "    \"\"\"Limpa uma string de histórico (de treino OU validação).\"\"\"\n",
    "    cleaned_str = history_str.replace('\\n', '').replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").strip()\n",
    "    page_ids = [item.strip() for item in re.split(r'[,\\s]+', cleaned_str) if item.strip()]\n",
    "    return page_ids\n",
    "\n",
    "# Cria copias dos dataframes originais para fazer a limpeza\n",
    "\n",
    "train_df_cleaned = train_df.copy()\n",
    "train_df_cleaned['history'] = train_df_cleaned['history'].apply(clean_history_string)\n",
    "\n",
    "validation_df_cleaned = validation_df.copy()\n",
    "validation_df_cleaned['history'] = validation_df_cleaned['history'].apply(clean_history_string)\n",
    "\n",
    "# Tratamento das outras colunas dos dataset de treinamento e converte pra array do numpy\n",
    "\n",
    "def parse_list_of_numbers_train(list_str):\n",
    "    \"\"\"Analisa com segurança uma representação em string de uma lista de números,\n",
    "       e *sempre* retorna um array NumPy.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_list = ast.literal_eval(list_str) # eval da string como python list\n",
    "        if isinstance(parsed_list, (int, float)):  # verifica se é um numero unico\n",
    "            return np.array([parsed_list])       # Cria o NumPy array de um item\n",
    "        else:\n",
    "            return np.array(parsed_list)         # Converte a lista para array do NumPy\n",
    "    except (ValueError, SyntaxError):\n",
    "        return np.array([])\n",
    "\n",
    "list_cols = ['timestampHistory', 'numberOfClicksHistory',\n",
    "             'timeOnPageHistory', 'scrollPercentageHistory', 'pageVisitsCountHistory']\n",
    "\n",
    "for col in list_cols:\n",
    "    train_df_cleaned[col] = train_df_cleaned[col].apply(parse_list_of_numbers_train)\n",
    "\n",
    "# Removendo a coluna duplicada timestampHistory_new\n",
    "train_df_cleaned = train_df_cleaned.drop(columns=['timestampHistory_new'], errors='ignore')\n",
    "\n",
    "# Tratamento das outras colunas do dataset de validação\n",
    "\n",
    "def parse_list_of_numbers_validation(list_str):\n",
    "    \"\"\"Analisa com segurança uma representação em string de uma lista de números,\n",
    "       tratando valores separados por espaço, e sempre retorna um array NumPy.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove colchetes e divide em espaços.\n",
    "        cleaned_str = list_str.replace(\"[\", \"\").replace(\"]\", \"\").strip()\n",
    "        # Trata o caso em que é um único número (sem espaços)\n",
    "        if ' ' not in cleaned_str:\n",
    "            return np.array([int(cleaned_str)]) \n",
    "        numbers = [int(item.strip()) for item in re.split(r'\\s+', cleaned_str) if item.strip()]\n",
    "        return np.array(numbers)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return np.array([])\n",
    "\n",
    "list_cols = ['timestampHistory']\n",
    "\n",
    "for col in list_cols:\n",
    "    validation_df_cleaned[col] = validation_df_cleaned[col].apply(parse_list_of_numbers_validation)\n",
    "\n",
    "# --- Carga e limpza de dados (itens)\n",
    "item_df_cleaned = item_df.copy() # faz uma copia do DF original para limpar\n",
    "item_df_cleaned['issued'] = pd.to_datetime(item_df_cleaned['issued'], errors='coerce')\n",
    "item_df_cleaned['modified'] = pd.to_datetime(item_df_cleaned['modified'], errors='coerce')\n",
    "item_df_cleaned = item_df_cleaned.drop(columns=['body', 'caption'], errors='ignore') # removendo colunas que não usaremos nesse exemplo\n",
    "\n",
    "# Validação que não ficou nada vazio, visto que o original não tinha linhas com celulas vazias.\n",
    "print(\"Number of empty histories in train_df_cleaned:\", train_df_cleaned['history'].apply(lambda x: len(x) == 0).sum())\n",
    "print(\"Number of empty histories in validation_df_cleaned:\", validation_df_cleaned['history'].apply(lambda x: len(x) == 0).sum())\n",
    "\n",
    "# Obtendo informações sobre o periodo que está sendo analisado\n",
    "min_train_timestamp = train_df_cleaned['timestampHistory'].apply(lambda x: np.nanmin(x)).min()  \n",
    "max_train_timestamp = train_df_cleaned['timestampHistory'].apply(lambda x: np.nanmax(x)).max()\n",
    "print(f\"\\nTrain Data Timestamp Range: Min = {min_train_timestamp}, Max = {max_train_timestamp}\")\n",
    "\n",
    "min_val_timestamp = validation_df_cleaned['timestampHistory'].apply(lambda x: np.nanmin(x)).min()\n",
    "max_val_timestamp = validation_df_cleaned['timestampHistory'].apply(lambda x: np.nanmax(x)).max()\n",
    "print(f\"Validation Data Timestamp Range: Min = {min_val_timestamp}, Max = {max_val_timestamp}\")\n",
    "\n",
    "print(\"\\nIn Datetime format:\")\n",
    "min_train_timestamp_dt = pd.to_datetime(min_train_timestamp, unit='ms')\n",
    "max_train_timestamp_dt = pd.to_datetime(max_train_timestamp, unit='ms')\n",
    "print(f\"Train Data Timestamp Range: Min = {min_train_timestamp_dt}, Max = {max_train_timestamp_dt}\")\n",
    "\n",
    "min_val_timestamp_dt = pd.to_datetime(min_val_timestamp, unit='ms')\n",
    "max_val_timestamp_dt = pd.to_datetime(max_val_timestamp, unit='ms')\n",
    "print(f\"Validation Data Timestamp Range: Min = {min_val_timestamp_dt}, Max = {max_val_timestamp_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataframes saved to Parquet files.\n"
     ]
    }
   ],
   "source": [
    "# Salvando datasets como parquets:\n",
    "train_df_cleaned.to_parquet('train_df_cleaned.parquet')\n",
    "validation_df_cleaned.to_parquet('validation_df_cleaned.parquet')\n",
    "item_df_cleaned.to_parquet('item_df_cleaned.parquet')\n",
    "\n",
    "print(\"Cleaned dataframes saved to Parquet files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train DataFrame Head:\n",
      "                                              userId    userType  historySize  \\\n",
      "0  f98d1132f60d46883ce49583257104d15ce723b3bbda21...  Non-Logged            3   \n",
      "1  2c1080975e257ed630e26679edbe4d5c850c65f3e09f65...  Non-Logged           60   \n",
      "2  0adffd7450d3b9840d8c6215f0569ad942e782fb19b805...      Logged          107   \n",
      "3  c1e8d644329a78ea1f994292db624c57980b2886cfbc2d...  Non-Logged           56   \n",
      "4  e777d1f31d4d955b63d60acc13df336d3903f52ab8f8f4...  Non-Logged            4   \n",
      "\n",
      "                                             history  \\\n",
      "0  [c8aab885-433d-4e46-8066-479f40ba7fb2, 68d2039...   \n",
      "1  [3325b5a1-979a-4cb3-82b6-63905c9edbe8, fe85605...   \n",
      "2  [04756569-593e-4133-a95a-83d35d43dbbd, 29b6b14...   \n",
      "3  [1f2b9c2f-a2d2-4192-b009-09065da8ec23, 0475656...   \n",
      "4  [bebdeb3e-1699-43e0-a1b8-989f5a6ab679, f4b484a...   \n",
      "\n",
      "                                    timestampHistory  \\\n",
      "0      [1657146417045, 1657146605778, 1657146698738]   \n",
      "1  [1656684240278, 1656761266729, 1656761528085, ...   \n",
      "2  [1656678946256, 1656701076495, 1656701882565, ...   \n",
      "3  [1658333312180, 1658404553818, 1658408449062, ...   \n",
      "4  [1658766608801, 1658766608801, 1660084035094, ...   \n",
      "\n",
      "                               numberOfClicksHistory  \\\n",
      "0                                       [76, 38, 41]   \n",
      "1  [7, 80, 2, 1, 7, 62, 26, 44, 4, 4, 14, 45, 13,...   \n",
      "2  [0, 0, 0, 0, 0, 44, 0, 0, 2, 1, 0, 0, 0, 44, 0...   \n",
      "3  [8, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 1, ...   \n",
      "4                                   [579, 579, 7, 2]   \n",
      "\n",
      "                                   timeOnPageHistory  \\\n",
      "0                              [20380, 21184, 35438]   \n",
      "1  [6049, 210489, 8672, 10000, 30000, 123007, 996...   \n",
      "2  [311274, 140000, 32515, 157018, 118689, 159243...   \n",
      "3  [182696, 91925, 30000, 273655, 126409, 42980, ...   \n",
      "4                     [801396, 801396, 10000, 10000]   \n",
      "\n",
      "                             scrollPercentageHistory  \\\n",
      "0                               [50.3, 18.18, 16.46]   \n",
      "1  [25.35, 45.66, 35.3, 28.05, 36.53, 47.57, 55.3...   \n",
      "2  [67.58, 47.22, 41.52, 63.09, 51.38, 65.11, 71....   \n",
      "3  [58.26, 72.66, 22.57, 59.89, 40.36, 36.35, 14....   \n",
      "4                        [78.74, 78.74, 16.71, 9.34]   \n",
      "\n",
      "                              pageVisitsCountHistory  \n",
      "0                                          [2, 1, 1]  \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, ...  \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, ...  \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "4                                       [7, 7, 1, 1]  \n",
      "\n",
      "Item DataFrame Head:\n",
      "                                   page  \\\n",
      "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
      "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
      "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
      "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
      "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
      "1  http://g1.globo.com/pa/santarem-regiao/noticia...   \n",
      "2  http://g1.globo.com/mundo/noticia/2022/07/08/e...   \n",
      "3  http://g1.globo.com/politica/noticia/2021/09/0...   \n",
      "4  http://g1.globo.com/politica/noticia/2021/09/1...   \n",
      "\n",
      "                     issued                  modified  \\\n",
      "0 2022-06-18 20:37:45+00:00 2023-04-15 00:02:08+00:00   \n",
      "1 2019-06-20 17:19:52+00:00 2023-06-16 20:19:15+00:00   \n",
      "2 2022-07-08 08:55:52+00:00 2023-04-15 04:25:39+00:00   \n",
      "3 2021-09-09 19:06:46+00:00 2023-06-07 17:44:54+00:00   \n",
      "4 2021-09-15 19:16:13+00:00 2023-06-07 17:43:39+00:00   \n",
      "\n",
      "                                               title  \n",
      "0  Caso Bruno e Dom: 3º suspeito tem prisão tempo...  \n",
      "1  Linguajar dos santarenos é diferenciado e chei...  \n",
      "2  Ex-premiê Shinzo Abe morre após ser baleado no...  \n",
      "3  Relator no STF, Fachin vota contra marco tempo...  \n",
      "4  \\nApós 2 votos, pedido de vista suspende julga...  \n",
      "\n",
      "Validation DataFrame Head\n",
      "                                              userId userType  \\\n",
      "0  e25fbee3a42d45a2914f9b061df3386b2ded2d8cc1f3d4...   Logged   \n",
      "1  d0afad7ea843d86597d822f0df1d39d31a3fea7c39fdee...   Logged   \n",
      "2  755062dd39a48809880cf363b04268c3af2c003088cde0...   Logged   \n",
      "3  ec1639851d99586c7f4da928deb49187303aec6e3b8d66...   Logged   \n",
      "4  a120515626fe5d12b22b7d5a7c5008912cc69284aa26cc...   Logged   \n",
      "\n",
      "                                             history  \\\n",
      "0  [be89a7da-d9fa-49d4-9fdc-388c27a15bc8, 01c59ff...   \n",
      "1             [77901133-aee7-4f7b-afc0-652231d76fe9]   \n",
      "2             [857aa90f-a7ec-410d-ba82-dfa4f85d4e71]   \n",
      "3  [b7b90e18-7613-4ca0-a8fc-fd69addfcd85, 835fdd8...   \n",
      "4  [9c764c3a-f9f8-4fb2-b2c4-6331eaeb3dd6, b8eba39...   \n",
      "\n",
      "                                    timestampHistory  \n",
      "0                     [1660533136590, 1660672113513]  \n",
      "1                                    [1660556860253]  \n",
      "2                                    [1660561649242]  \n",
      "3  [1660533830245, 1660540831707, 1660542659111, ...  \n",
      "4      [1660548813953, 1660572329731, 1660594848200]  \n",
      "Missing values in train_df AFTER cleaning:\n",
      "userId                     0\n",
      "userType                   0\n",
      "historySize                0\n",
      "history                    0\n",
      "timestampHistory           0\n",
      "numberOfClicksHistory      0\n",
      "timeOnPageHistory          0\n",
      "scrollPercentageHistory    0\n",
      "pageVisitsCountHistory     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in item_df AFTER cleaning:\n",
      "page        0\n",
      "url         0\n",
      "issued      0\n",
      "modified    0\n",
      "title       0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in validation_df AFTER cleaning:\n",
      "userId              0\n",
      "userType            0\n",
      "history             0\n",
      "timestampHistory    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificando head dos datasets limpos para comparar com o original, após a limpeza\n",
    "print(\"\\nTrain DataFrame Head:\")\n",
    "print(train_df_cleaned.head())\n",
    "print(\"\\nItem DataFrame Head:\")\n",
    "print(item_df_cleaned.head())\n",
    "print(\"\\nValidation DataFrame Head\")\n",
    "print(validation_df_cleaned.head())\n",
    "\n",
    "#Verificando novamente se ficou algo vazio, que de acordo com nossa tratativa de erros significa que algo deu errado se não for zero.\n",
    "\n",
    "print(\"Missing values in train_df AFTER cleaning:\")\n",
    "print(train_df_cleaned.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in item_df AFTER cleaning:\")\n",
    "print(item_df_cleaned.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in validation_df AFTER cleaning:\")\n",
    "print(validation_df_cleaned.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
